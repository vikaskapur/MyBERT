{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_tokenizer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMRkIFhuTM9M"
      },
      "source": [
        "# Stage 1: Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76HfPILdC5lD"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1h4YVFfDd1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d75d650-2c6a-4bf8-f8aa-72a0b7066075"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 18.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 136 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30535 sha256=7992f23268ff082b0da57b96b5d97ed36a0719b4f64f8e4cb113d4a781ce7943\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=fc5509f8e06c58ae60f7082c9388e867817e01124326a126333185069b278334\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=7005237342f57faaec690bd11dfb71ca62fa6e7c02d4f1d6214fa65f507e2c5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 13.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMqTwu9jENrO"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0_xu0I3jFP9"
      },
      "source": [
        "# Stage 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FifCe97pTVql"
      },
      "source": [
        "## Loading files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S0lOeu8TbnP"
      },
      "source": [
        "We import files from our personal Google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRCxQui8Gqi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9624fab2-39c1-44da-8a9f-b8129d83011a"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6iT5nxDHLRz"
      },
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "data = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/Datasets/SentimentData/training.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKnCVewUIBkc"
      },
      "source": [
        "data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
        "          axis=1,\n",
        "          inplace=True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWWUo_XVeqoG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "814460c3-eaab-4c28-82cb-c9e0bee333b4"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-61ed3ba6-1067-4b63-b324-729e79eb4a4b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61ed3ba6-1067-4b63-b324-729e79eb4a4b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61ed3ba6-1067-4b63-b324-729e79eb4a4b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61ed3ba6-1067-4b63-b324-729e79eb4a4b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[data.sentiment == 4].head()"
      ],
      "metadata": {
        "id": "hq5b7ygaiZDn",
        "outputId": "edab2ee7-884e-4d62-df8d-731b2a52777a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2bd203ac-45c7-4114-9185-0b4492dcef5c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>800000</th>\n",
              "      <td>4</td>\n",
              "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800001</th>\n",
              "      <td>4</td>\n",
              "      <td>im meeting up with one of my besties tonight! ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800002</th>\n",
              "      <td>4</td>\n",
              "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800003</th>\n",
              "      <td>4</td>\n",
              "      <td>Being sick can be really cheap when it hurts t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>800004</th>\n",
              "      <td>4</td>\n",
              "      <td>@LovesBrooklyn2 he has that effect on everyone</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bd203ac-45c7-4114-9185-0b4492dcef5c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2bd203ac-45c7-4114-9185-0b4492dcef5c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2bd203ac-45c7-4114-9185-0b4492dcef5c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        sentiment                                               text\n",
              "800000          4       I LOVE @Health4UandPets u guys r the best!! \n",
              "800001          4  im meeting up with one of my besties tonight! ...\n",
              "800002          4  @DaRealSunisaKim Thanks for the Twitter add, S...\n",
              "800003          4  Being sick can be really cheap when it hurts t...\n",
              "800004          4    @LovesBrooklyn2 he has that effect on everyone "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Quzx5tnjUtl"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8hlexmRjXIS"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBSUDL-UP-W_"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    # Delete the @\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    # Delete URL links\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    # Just keep letters and important punctuation\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    # Remove additional spaces\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jiMaQsLWiTS"
      },
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.text]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaqLE0fdWtni"
      },
      "source": [
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean[:10]"
      ],
      "metadata": {
        "id": "17K7LbU2j1YP",
        "outputId": "a05fddc9-dfe5-4528-a388-3a9e25ae09bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\" Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\",\n",
              " \"is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!\",\n",
              " ' I dived many times for the ball. Managed to save The rest go out of bounds',\n",
              " 'my whole body feels itchy and like its on fire ',\n",
              " \" no it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \",\n",
              " ' not the whole crew ',\n",
              " 'Need a hug ',\n",
              " \" hey long time no see! Yes.. Rains a bit only a bit LOL I'm fine thanks how's you ?\",\n",
              " \" K nope they didn't have it \",\n",
              " ' que me muera ? ']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eh7sIquja5t"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV73IkgKUCmV"
      },
      "source": [
        "We need to create a BERT layer to have access to meta data for the tokenizer (like vocab size)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wry-st-HMN0"
      },
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"lower case : {do_lower_case}\")\n",
        "print(\"vocab file : {vocab_file}\")\n",
        "with open(vocab_file, \"r\") as f:\n",
        "  x = f.readlines()\n",
        "  \n",
        "  print(\"Vocab length: \", len(x))\n",
        "  print(\"Some words: \", x[5000:5010])\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "PRlYoMDYeUuO",
        "outputId": "33b780d9-342a-4543-83f7-4dd2c1690467",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lower case : {do_lower_case}\n",
            "vocab file : {vocab_file}\n",
            "Vocab length:  30522\n",
            "Some words:  ['knight\\n', 'lap\\n', 'survey\\n', 'ma\\n', '##ow\\n', 'noise\\n', 'billy\\n', '##ium\\n', 'shooting\\n', 'guide\\n']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.tokenize(\"what will be next variant after covid omicron?\"))"
      ],
      "metadata": {
        "id": "qJl1dO5ZkzFf",
        "outputId": "6a805e79-8184-4a92-990d-e79d5c292836",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['what', 'will', 'be', 'next', 'variant', 'after', 'co', '##vid', 'om', '##ic', '##ron', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LggMv7k7Z3Ij"
      },
      "source": [
        "def encode_sentence(sent):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sent))"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGfTo5uIa2is"
      },
      "source": [
        "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-4oGSu5jxUi"
      },
      "source": [
        "### Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaVPF9-rUTqZ"
      },
      "source": [
        "We will create padded batches (so we pad sentences for each batch inpedendently), this way we add the minimum of padding tokens possible. For that, we sort sentences by length, apply padded_batches and then shuffle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS_f6gWsLfLM"
      },
      "source": [
        "data_with_len = [[sent, data_labels[i], len(sent)]\n",
        "                 for i, sent in enumerate(data_inputs)]\n",
        "random.shuffle(data_with_len)\n",
        "data_with_len.sort(key=lambda x: x[2])\n",
        "sorted_all = [(sent_lab[0], sent_lab[1])\n",
        "              for sent_lab in data_with_len if sent_lab[2] > 7]"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0uJJg8lSQR"
      },
      "source": [
        "# A list is a type of iterator so it can be used as generator for a dataset\n",
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF74g5hpYzaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beea3d2b-0b48-492e-8c3f-584c07d6172b"
      },
      "source": [
        "next(iter(all_dataset))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=int32, numpy=array([2003, 5948, 4157, 1012, 3008, 2272, 2188, 3892], dtype=int32)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHAhlfTlrcj"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ktdxCEm4Yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6dc1e13-211b-4a66-c0c9-d24f72f7ae33"
      },
      "source": [
        "next(iter(all_batched))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 8), dtype=int32, numpy=\n",
              " array([[ 2003,  5948,  4157,  1012,  3008,  2272,  2188,  3892],\n",
              "        [ 2572,  1012,  2086,  3283,  1045,  2001,  2141,  1012],\n",
              "        [ 5093,  2059,  4895, 23947,  2075,  2013,  2026,  4440],\n",
              "        [ 2026,  6896,  2001,  8680,  2006,  3345,  2188,  2085],\n",
              "        [ 1012,  1012,  1012,  2053,  3696,  1997, 11415,  2295],\n",
              "        [ 2026,  2767,  2180,  2102,  2735,  2037,  3042,  2006],\n",
              "        [ 1045,  1049,  2061,  2894,  1998,  2026,  4268,  5777],\n",
              "        [ 2033,  2205,  2021,  1996,  6440,  7165,  8271,  2033],\n",
              "        [ 4365, 10047,  8239,  5458,  8909,  2243,  2339,  2593],\n",
              "        [ 2009,  2428,  2196,  3092,  2039,  2108,  2008,  2569],\n",
              "        [ 1999, 26353,  2007,  2026,  2567,  1998,  1996,  2137],\n",
              "        [ 2429,  2000,  2600,  2316, 10047,  1005, 27503,  1005],\n",
              "        [ 1045,  2293,  3348,  5850,  1998,  2600, 16118, 14511],\n",
              "        [ 1045,  2572,  2036,  2012,  8771,   999,  4283,  3071],\n",
              "        [17012,  1045,  2293,  2047,  3182,  1012,  4283,   999],\n",
              "        [ 2204,  2147,  1012,  1012,  3811,  7622,  2011,  2017],\n",
              "        [ 1045,  4771,  4615,  3860,  2565,  4718,  2140,  1012],\n",
              "        [24218,  2066,  2252,  2189,  2096, 24471,  4550,  2378],\n",
              "        [ 3531,  2643,  2292,  2033,  2131,  1037,  2488,  3105],\n",
              "        [ 1045,  1005,  1049,  5458,  1012,  2021,  4165,  4569],\n",
              "        [22091,  2232,  1045,  8814,  2615,  8814,  2205,  1012],\n",
              "        [ 2453,  2031,  2657,  2009,  2021,  3531,  2079,  4863],\n",
              "        [ 2481,  1005,  1056,  2424,  2008,  2711,  2006, 10474],\n",
              "        [ 5128,  5131, 12817,  2000,  1037,  6136,  2077,  3405],\n",
              "        [ 2204,  2933,   999,  1998,  1037,  2793,  2004,  2092],\n",
              "        [ 3201,  2005,  2394,  3259,  2204,  6735,  2153,  3071],\n",
              "        [ 2758, 14118,  3475,  1005,  1056,  2008,  2919,  1012],\n",
              "        [ 1045,  3246,  2017,  2031,  2051,  2000,  3102,  1012],\n",
              "        [ 7592,   999,  2033,  2205,  2129,  1054,  1057,  1029],\n",
              "        [ 5830,  1998,  4274,  2003,  2041,  1012,  1012,  1012],\n",
              "        [ 2009,  1005,  1055,  2559,  2066,  2009,  2097,  1012],\n",
              "        [ 7632,  4202,  2129,  1005,  1055,  2166,  1029,  1029]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "        0, 1, 1, 1, 1, 1, 1, 0, 0, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPqJeYpmfcv"
      },
      "source": [
        "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxONsFVHkFLU"
      },
      "source": [
        "# Stage 3: Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6DD3k3qPLDQ"
      },
      "source": [
        "class DCNN(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocab_size,\n",
        "                 emb_dim=128,\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"dcnn\"):\n",
        "        super(DCNN, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocab_size,\n",
        "                                          emb_dim)\n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embedding(inputs)\n",
        "        x_1 = self.bigram(x) # (batch_size, nb_filters, seq_len-1)\n",
        "        x_1 = self.pool(x_1) # (batch_size, nb_filters)\n",
        "        x_2 = self.trigram(x) # (batch_size, nb_filters, seq_len-2)\n",
        "        x_2 = self.pool(x_2) # (batch_size, nb_filters)\n",
        "        x_3 = self.fourgram(x) # (batch_size, nb_filters, seq_len-3)\n",
        "        x_3 = self.pool(x_3) # (batch_size, nb_filters)\n",
        "        \n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSix1l4jkIxp"
      },
      "source": [
        "# Stage 4: Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhfUFvWEPOIf"
      },
      "source": [
        "VOCAB_SIZE = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMtdiWmwv6rD"
      },
      "source": [
        "Dcnn = DCNN(vocab_size=VOCAB_SIZE,\n",
        "            emb_dim=EMB_DIM,\n",
        "            nb_filters=NB_FILTERS,\n",
        "            FFN_units=FFN_UNITS,\n",
        "            nb_classes=NB_CLASSES,\n",
        "            dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apbd7FrwPYo"
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78cceSGCw1XC"
      },
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/BERT_UDEMY/models/cnn_sentiment/\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest Checkpoint restored!\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YIF5trzx7RA"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrT8oWZzQNmW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40f1dfd1-0a90-467d-ed7d-0ed955bdce5a"
      },
      "source": [
        "Dcnn.fit(train_dataset,\n",
        "         epochs=NB_EPOCHS,\n",
        "         callbacks=[MyCustomCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "  37196/Unknown - 751s 19ms/step - loss: 0.4291 - accuracy: 0.8022Checkpoint saved at /content/drive/MyDrive/BERT_UDEMY/models/cnn_sentiment/.\n",
            "37196/37196 [==============================] - 752s 19ms/step - loss: 0.4291 - accuracy: 0.8022\n",
            "Epoch 2/5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IiDW919kQQK"
      },
      "source": [
        "# Stage 5: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MthhNfnG1TPV"
      },
      "source": [
        "results = Dcnn.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jrRvtl1xuk"
      },
      "source": [
        "def get_prediction(sentence):\n",
        "    tokens = encode_sentence(sentence)\n",
        "    inputs = tf.expand_dims(tokens, 0)\n",
        "\n",
        "    output = Dcnn(inputs, training=False)\n",
        "\n",
        "    sentiment = math.floor(output*2)\n",
        "\n",
        "    if sentiment == 0:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: negative.\".format(\n",
        "            output))\n",
        "    elif sentiment == 1:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: positive.\".format(\n",
        "            output))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk8V2bdvwfCv"
      },
      "source": [
        "get_prediction(\"This movie was pretty interesting.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgSppeGParJ"
      },
      "source": [
        "get_prediction(\"I'd rather not do that again.\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}