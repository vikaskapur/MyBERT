{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert_embedding.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMRkIFhuTM9M"
      },
      "source": [
        "# Stage 1: Importing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76HfPILdC5lD"
      },
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import random\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1h4YVFfDd1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e410ed-3f07-4d21-a9f6-87d9ca06c584"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[?25l\r\u001b[K     |████████                        | 10 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 41 kB 127 kB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.62.3)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30535 sha256=e0aa1beaf91eac3865a2339f63045b65b5996ac7ef999f26d171165b92a760db\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/b6/e5/8c76ec779f54bc5c2f1b57d2200bb9c77616da83873e8acb53\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19472 sha256=7c3721bc42c7b2e534c51f21ee64b4b70015eb336f9a7067d7bb574240618014\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/fc/d2/a44fff33af0f233d7def6e7de413006d57c10e10ad736fe8f5\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7911 sha256=61b343eea9a246cedc2aa47842528edf88173b4659670b528aab2911265c092a\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/11/67/33cc51bbee127cb8fb2ba549cd29109b2f22da43ddf9969716\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 6.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMqTwu9jENrO"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0_xu0I3jFP9"
      },
      "source": [
        "# Stage 2: Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FifCe97pTVql"
      },
      "source": [
        "## Loading files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S0lOeu8TbnP"
      },
      "source": [
        "We import files from our personal Google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRCxQui8Gqi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f5dae0-8d0f-4f68-8424-55d26030c7ef"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6iT5nxDHLRz"
      },
      "source": [
        "cols = [\"sentiment\", \"id\", \"date\", \"query\", \"user\", \"text\"]\n",
        "data = pd.read_csv(\n",
        "    \"/content/drive/MyDrive/Datasets/SentimentData/training.csv\",\n",
        "    header=None,\n",
        "    names=cols,\n",
        "    engine=\"python\",\n",
        "    encoding=\"latin1\"\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKnCVewUIBkc"
      },
      "source": [
        "data.drop([\"id\", \"date\", \"query\", \"user\"],\n",
        "          axis=1,\n",
        "          inplace=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWWUo_XVeqoG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "c8265c20-c1eb-4d2b-c01a-a82a0c17c02f"
      },
      "source": [
        "data.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ae543296-602e-48db-bd62-2958a9e1cb01\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae543296-602e-48db-bd62-2958a9e1cb01')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae543296-602e-48db-bd62-2958a9e1cb01 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae543296-602e-48db-bd62-2958a9e1cb01');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   sentiment                                               text\n",
              "0          0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1          0  is upset that he can't update his Facebook by ...\n",
              "2          0  @Kenichan I dived many times for the ball. Man...\n",
              "3          0    my whole body feels itchy and like its on fire \n",
              "4          0  @nationwideclass no, it's not behaving at all...."
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Quzx5tnjUtl"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8hlexmRjXIS"
      },
      "source": [
        "### Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBSUDL-UP-W_"
      },
      "source": [
        "def clean_tweet(tweet):\n",
        "    tweet = BeautifulSoup(tweet, \"lxml\").get_text()\n",
        "    # Delete the @\n",
        "    tweet = re.sub(r\"@[A-Za-z0-9]+\", ' ', tweet)\n",
        "    # Delete URL links\n",
        "    tweet = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', tweet)\n",
        "    # Just keep letters and important punctuation\n",
        "    tweet = re.sub(r\"[^a-zA-Z.!?']\", ' ', tweet)\n",
        "    # Remove additional spaces\n",
        "    tweet = re.sub(r\" +\", ' ', tweet)\n",
        "    return tweet"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jiMaQsLWiTS"
      },
      "source": [
        "data_clean = [clean_tweet(tweet) for tweet in data.text]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaqLE0fdWtni"
      },
      "source": [
        "data_labels = data.sentiment.values\n",
        "data_labels[data_labels == 4] = 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'No of training examples : {len(data_clean)}')\n",
        "\n",
        "for i in range(5):\n",
        "  print(f'{i}: Original: {data.iloc[i][\"text\"]}')\n",
        "  print(f'{i}: Cleaned: {data_clean[i]}')\n",
        "  print(f'------')\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boE9-j2DKGgi",
        "outputId": "f65efe51-5741-4827-a2a1-b61eca1ee8ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of training examples : 1600000\n",
            "0: Original: @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\n",
            "0: Cleaned:  Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\n",
            "------\n",
            "1: Original: is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\n",
            "1: Cleaned: is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!\n",
            "------\n",
            "2: Original: @Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds\n",
            "2: Cleaned:  I dived many times for the ball. Managed to save The rest go out of bounds\n",
            "------\n",
            "3: Original: my whole body feels itchy and like its on fire \n",
            "3: Cleaned: my whole body feels itchy and like its on fire \n",
            "------\n",
            "4: Original: @nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \n",
            "4: Cleaned:  no it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eh7sIquja5t"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pV73IkgKUCmV"
      },
      "source": [
        "We need to create a BERT layer to have access to meta data for the tokenizer (like vocab size)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wry-st-HMN0"
      },
      "source": [
        "FullTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH9XmkM4WbUm"
      },
      "source": [
        "We only use the first sentence for BERT inputs so we add the CLS token at the beginning and the SEP token at the end of each sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LggMv7k7Z3Ij"
      },
      "source": [
        "def encode_sentence(sent):\n",
        "    return [\"[CLS]\"] + tokenizer.tokenize(sent) + [\"[SEP]\"]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGfTo5uIa2is"
      },
      "source": [
        "data_inputs = [encode_sentence(sentence) for sentence in data_clean]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "  print(f'{i} Data: {data_clean[i]}')\n",
        "  print(f'{i} Data Encoded: {data_inputs[i]}')\n",
        "  print(f'----')\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBm4FGKuNVyn",
        "outputId": "df3fbe1e-b593-4f5b-97bf-a64679185c7a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Data:  Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\n",
            "0 Data Encoded: ['[CLS]', 'aw', '##w', '##w', 'that', \"'\", 's', 'a', 'bum', '##mer', '.', 'you', 'should', '##a', 'got', 'david', 'carr', 'of', 'third', 'day', 'to', 'do', 'it', '.', 'd', '[SEP]']\n",
            "----\n",
            "1 Data: is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!\n",
            "1 Data Encoded: ['[CLS]', 'is', 'upset', 'that', 'he', 'can', \"'\", 't', 'update', 'his', 'facebook', 'by', 'text', '##ing', 'it', '.', '.', '.', 'and', 'might', 'cry', 'as', 'a', 'result', 'school', 'today', 'also', '.', 'blah', '!', '[SEP]']\n",
            "----\n",
            "2 Data:  I dived many times for the ball. Managed to save The rest go out of bounds\n",
            "2 Data Encoded: ['[CLS]', 'i', 'dive', '##d', 'many', 'times', 'for', 'the', 'ball', '.', 'managed', 'to', 'save', 'the', 'rest', 'go', 'out', 'of', 'bounds', '[SEP]']\n",
            "----\n",
            "3 Data: my whole body feels itchy and like its on fire \n",
            "3 Data Encoded: ['[CLS]', 'my', 'whole', 'body', 'feels', 'it', '##chy', 'and', 'like', 'its', 'on', 'fire', '[SEP]']\n",
            "----\n",
            "4 Data:  no it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. \n",
            "4 Data Encoded: ['[CLS]', 'no', 'it', \"'\", 's', 'not', 'be', '##ha', '##ving', 'at', 'all', '.', 'i', \"'\", 'm', 'mad', '.', 'why', 'am', 'i', 'here', '?', 'because', 'i', 'can', \"'\", 't', 'see', 'you', 'all', 'over', 'there', '.', '[SEP]']\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-4oGSu5jxUi"
      },
      "source": [
        "### Dataset creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHXwqimXWwH3"
      },
      "source": [
        "We need to create the 3 different inputs for each sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GEu2pEEW23q"
      },
      "source": [
        "def get_ids(tokens):\n",
        "    return tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "def get_mask(tokens):\n",
        "    return np.char.not_equal(tokens, \"[PAD]\").astype(int)\n",
        "\n",
        "def get_segments(tokens):\n",
        "    seg_ids = []\n",
        "    current_seg_id = 0\n",
        "    for tok in tokens:\n",
        "        seg_ids.append(current_seg_id)\n",
        "        if tok == \"[SEP]\":\n",
        "            current_seg_id = 1-current_seg_id # convert 1 into 0 and vice versa\n",
        "    return seg_ids"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_tokens = data_inputs[3]\n",
        "print(f'tokens : {test_tokens}')\n",
        "print(f'get_ids : {get_ids(test_tokens)}')\n",
        "print(f'get_masks : {get_mask(test_tokens)}')\n",
        "print(f'get_segments: {get_segments(test_tokens)}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9Ibfhf1PdRE",
        "outputId": "84c8064c-5dd1-47ac-9d14-862f12429c5a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens : ['[CLS]', 'my', 'whole', 'body', 'feels', 'it', '##chy', 'and', 'like', 'its', 'on', 'fire', '[SEP]']\n",
            "get_ids : [101, 2026, 2878, 2303, 5683, 2009, 11714, 1998, 2066, 2049, 2006, 2543, 102]\n",
            "get_masks : [1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "get_segments: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaVPF9-rUTqZ"
      },
      "source": [
        "We will create padded batches (so we pad sentences for each batch inpedendently), this way we add the minimum of padding tokens possible. For that, we sort sentences by length, apply padded_batches and then shuffle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS_f6gWsLfLM"
      },
      "source": [
        "data_with_len = [[sent, data_labels[i], len(sent)]\n",
        "                 for i, sent in enumerate(data_inputs)]\n",
        "random.shuffle(data_with_len)\n",
        "data_with_len.sort(key=lambda x: x[2])\n",
        "sorted_all = [([get_ids(sent_lab[0]),\n",
        "                get_mask(sent_lab[0]),\n",
        "                get_segments(sent_lab[0])],\n",
        "               sent_lab[1])\n",
        "              for sent_lab in data_with_len if sent_lab[2] > 7]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training examples (after filtering): {len(sorted_all)}')\n",
        "print(f'{0} Example: {sorted_all[0]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBe7T51MRBwp",
        "outputId": "e9cde8cc-47d0-45cd-d45d-8ecb37c9ceb6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training examples (after filtering): 1444341\n",
            "0 Example: ([[101, 1045, 4299, 1045, 2001, 1999, 6278, 102], array([1, 1, 1, 1, 1, 1, 1, 1]), [0, 0, 0, 0, 0, 0, 0, 0]], 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry0uJJg8lSQR"
      },
      "source": [
        "# A list is a type of iterator so it can be used as generator for a dataset\n",
        "all_dataset = tf.data.Dataset.from_generator(lambda: sorted_all,\n",
        "                                             output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF74g5hpYzaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e20b8b6-94a7-4422-d092-6a803c2d5bc6"
      },
      "source": [
        "next(iter(all_dataset))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
              " array([[ 101, 1045, 4299, 1045, 2001, 1999, 6278,  102],\n",
              "        [   1,    1,    1,    1,    1,    1,    1,    1],\n",
              "        [   0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(), dtype=int32, numpy=0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzHAhlfTlrcj"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "all_batched = all_dataset.padded_batch(BATCH_SIZE, padded_shapes=((3, None), ()))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3ktdxCEm4Yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd3d68b-59ae-491b-d0cd-53e9958f1b5d"
      },
      "source": [
        "next(iter(all_batched))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 3, 8), dtype=int32, numpy=\n",
              " array([[[  101,  1045,  4299,  1045,  2001,  1999,  6278,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2012,  2147,  2007, 12476, 25358,  2891,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2074,  2288, 18666,  2011, 12082,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2204,  2851,  2031,  1037,  3835,  2154,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  4394,  2026,  3336,  3016,  3016,   999,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  6151,  2229, 26775, 18410,  3468,  5346,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  6911,  8040, 26036,  4757, 18318,  8490,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2026,  2482,  2038,  2351, 14141,  2094,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2129,  2024,  2017,  2651,   999,  1029,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1998,  7592,  2000,  2017,  2035,   999,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2667, 10474,  2005,  1996,  2034,  2051,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2851,  1012,  2439,  1037, 22399,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2272,  2006,   999,  3582,  2033,   999,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101, 25871, 10930,   999,  2031,  4569,  9483,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2054,  1037,  2307,  2868,  2016,  2038,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2128,  2017,  1005,  2128,  2428,  1037,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1045,  2064,  3637,  1999,  3521,   999,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2025,  2033,  1045,  1005,  1049,  4389,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2091, 24170,  2094,  2026, 20907,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  6186,  1996,  5394,  3084,  2033, 13277,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  4399,  1012,  2059,  2346,  3231,  2044,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2074,  2018,  2010,  6105,  2579,  2185,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2067,  2000,  2082,  2005,  2033,   999,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101, 15030,  4869,  2054,  2015,  2039,  1029,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2017,  2053,  2234,  2000,  2156,  2033,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1049,  1045, 24501,  4765,  2115,  7615,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  5683, 28679,  2007,  2256,  3570,  1051,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2061,  3407,  8906,  2180,  2197,  2305,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  3631,  2026,  4060,  1012,  1012,  1012,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  2394, 11360,  4826,   999,  2821,  2053,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1046,  3367,  2288,  2026,  1043, 10651,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]],\n",
              " \n",
              "        [[  101,  1045,  1005,  1049,  1999,  2026,  5783,   102],\n",
              "         [    1,     1,     1,     1,     1,     1,     1,     1],\n",
              "         [    0,     0,     0,     0,     0,     0,     0,     0]]],\n",
              "       dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
              "        0, 1, 0, 1, 0, 1, 0, 0, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrPqJeYpmfcv"
      },
      "source": [
        "NB_BATCHES = math.ceil(len(sorted_all) / BATCH_SIZE)\n",
        "NB_BATCHES_TEST = NB_BATCHES // 10\n",
        "all_batched.shuffle(NB_BATCHES)\n",
        "test_dataset = all_batched.take(NB_BATCHES_TEST)\n",
        "train_dataset = all_batched.skip(NB_BATCHES_TEST)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'No of batches: {NB_BATCHES}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Te-5VpJ2TAVc",
        "outputId": "1cb20d55-ebfa-4a71-da1d-9eec0e3e671d"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of batches: 45136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxONsFVHkFLU"
      },
      "source": [
        "# Stage 3: Model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rutu68oHXdzy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8095f9a7-f53a-4a28-d15d-5e9019b86dbe"
      },
      "source": [
        "my_sent = [\"[CLS]\"] + tokenizer.tokenize(\"Roses are red.\") + [\"[SEP]\"]\n",
        "bert_layer([tf.expand_dims(tf.cast(get_ids(my_sent), tf.int32), 0),\n",
        "            tf.expand_dims(tf.cast(get_mask(my_sent), tf.int32), 0),\n",
        "            tf.expand_dims(tf.cast(get_segments(my_sent), tf.int32), 0)])"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[-9.27935421e-01, -4.10335243e-01, -9.65754986e-01,\n",
              "          9.07317698e-01,  8.12913716e-01, -1.74174413e-01,\n",
              "          9.11234379e-01,  3.41952085e-01, -8.74521196e-01,\n",
              "         -9.99989390e-01, -7.78409779e-01,  9.69385147e-01,\n",
              "          9.86160517e-01,  6.36963248e-01,  9.48631287e-01,\n",
              "         -7.51192927e-01, -4.58339483e-01, -7.08104432e-01,\n",
              "          4.62098330e-01, -6.57926798e-01,  7.60414362e-01,\n",
              "          9.99994695e-01, -3.96861076e-01,  3.44166100e-01,\n",
              "          6.16488576e-01,  9.94400024e-01, -7.76633620e-01,\n",
              "          9.38316405e-01,  9.59452212e-01,  7.32879162e-01,\n",
              "         -6.93436623e-01,  2.93080419e-01, -9.93785441e-01,\n",
              "         -1.64551854e-01, -9.67019558e-01, -9.95549619e-01,\n",
              "          5.32935262e-01, -6.88060999e-01,  1.34716183e-02,\n",
              "          2.98195966e-02, -9.18356478e-01,  4.20526266e-01,\n",
              "          9.99988914e-01,  2.52676159e-01,  6.06235325e-01,\n",
              "         -3.50750089e-01, -1.00000000e+00,  4.97585446e-01,\n",
              "         -8.95187318e-01,  9.62560892e-01,  9.43730593e-01,\n",
              "          9.03285503e-01,  1.54699489e-01,  5.86143374e-01,\n",
              "          5.80860257e-01, -4.05053079e-01, -2.76642758e-02,\n",
              "          2.98045993e-01, -2.83075690e-01, -6.47424221e-01,\n",
              "         -6.51523709e-01,  5.43847203e-01, -9.56302047e-01,\n",
              "         -9.22750235e-01,  9.61462915e-01,  8.27475488e-01,\n",
              "         -3.50112408e-01, -4.06405658e-01, -8.74317139e-02,\n",
              "         -9.98739973e-02,  8.96688223e-01,  3.00931573e-01,\n",
              "         -1.51129454e-01, -8.52713406e-01,  8.09592366e-01,\n",
              "          4.00989056e-01, -6.61605895e-01,  1.00000000e+00,\n",
              "         -6.16246045e-01, -9.86407101e-01,  8.90942812e-01,\n",
              "          8.11157644e-01,  5.81394732e-01, -6.33873463e-01,\n",
              "          3.78198117e-01, -1.00000000e+00,  6.76351190e-01,\n",
              "         -2.30612561e-01, -9.92552519e-01,  3.85461092e-01,\n",
              "          6.57650590e-01, -2.90105730e-01,  4.46832448e-01,\n",
              "          6.28524184e-01, -5.58409393e-01, -6.65295124e-01,\n",
              "         -4.72272277e-01, -9.28039253e-01, -3.54472399e-01,\n",
              "         -6.19735837e-01,  1.24534748e-01, -3.48905653e-01,\n",
              "         -4.23184097e-01, -4.20834869e-01,  4.56588507e-01,\n",
              "         -6.14470840e-01, -5.15242875e-01,  5.01909912e-01,\n",
              "          4.29147631e-01,  7.59821892e-01,  4.37516540e-01,\n",
              "         -4.33598131e-01,  6.30961835e-01, -9.59743142e-01,\n",
              "          7.73877323e-01, -3.95737767e-01, -9.87354457e-01,\n",
              "         -6.73180223e-01, -9.92996395e-01,  7.77800024e-01,\n",
              "         -5.05856097e-01, -3.19990784e-01,  9.69388664e-01,\n",
              "         -3.51620764e-01,  3.79092097e-01, -2.21649349e-01,\n",
              "         -9.51505601e-01, -1.00000000e+00, -8.80426705e-01,\n",
              "         -8.34713042e-01, -2.77321547e-01, -4.70461220e-01,\n",
              "         -9.83711839e-01, -9.56730187e-01,  6.61120832e-01,\n",
              "          9.56025779e-01,  1.62189156e-01,  9.99961555e-01,\n",
              "         -5.11205792e-01,  9.59530532e-01, -5.58610141e-01,\n",
              "         -8.00221145e-01,  8.48543704e-01, -5.58320343e-01,\n",
              "          8.33738267e-01,  2.63148993e-01, -7.33846605e-01,\n",
              "          3.16189587e-01, -4.83305901e-01,  6.87450171e-01,\n",
              "         -7.94889688e-01, -3.81298304e-01, -8.71706128e-01,\n",
              "         -9.49487984e-01, -3.62460077e-01,  9.51175570e-01,\n",
              "         -7.62520552e-01, -9.61278081e-01, -1.53294399e-01,\n",
              "         -4.02463347e-01, -5.69815338e-01,  8.52475822e-01,\n",
              "          7.99817860e-01,  5.33586383e-01, -6.96546674e-01,\n",
              "          4.84272420e-01,  2.24440813e-01,  7.31195211e-01,\n",
              "         -8.18207800e-01, -3.58149707e-01,  5.32028437e-01,\n",
              "         -4.41676021e-01, -9.25720930e-01, -9.87607300e-01,\n",
              "         -5.07007539e-01,  5.31485438e-01,  9.93827164e-01,\n",
              "          7.66175091e-01,  4.12393063e-01,  8.83270264e-01,\n",
              "         -3.85666341e-01,  8.81850243e-01, -9.67345119e-01,\n",
              "          9.86407459e-01, -3.13535452e-01,  3.57363969e-01,\n",
              "         -6.57590151e-01,  2.70097196e-01, -8.59112978e-01,\n",
              "          2.32004032e-01,  8.62852871e-01, -9.03662443e-01,\n",
              "         -7.94610023e-01, -2.82699019e-01, -4.76583719e-01,\n",
              "         -5.01097381e-01, -8.80422235e-01,  5.45585990e-01,\n",
              "         -4.41977382e-01, -5.77728927e-01, -1.25809863e-01,\n",
              "          9.06031907e-01,  9.80562150e-01,  8.44253302e-01,\n",
              "          5.20119667e-01,  7.80579388e-01, -9.23414171e-01,\n",
              "         -5.87243497e-01,  2.34754547e-01,  2.97746599e-01,\n",
              "          3.54463696e-01,  9.96218562e-01, -8.01237524e-01,\n",
              "         -2.79998362e-01, -9.39948857e-01, -9.83751953e-01,\n",
              "          3.82992662e-02, -9.28821802e-01, -2.94137686e-01,\n",
              "         -7.00600803e-01,  7.67863750e-01, -3.51921946e-01,\n",
              "          6.57684028e-01,  5.54107010e-01, -9.90459323e-01,\n",
              "         -7.80434012e-01,  5.50272763e-01, -5.03932953e-01,\n",
              "          5.56852520e-01, -3.53224248e-01,  7.86349893e-01,\n",
              "          9.69607055e-01, -6.54101908e-01,  7.34232724e-01,\n",
              "          8.81996453e-01, -9.14772034e-01, -7.82534540e-01,\n",
              "          8.52741122e-01, -4.38667655e-01,  8.24172139e-01,\n",
              "         -7.77354538e-01,  9.91627038e-01,  9.48048532e-01,\n",
              "          7.74401486e-01, -9.52811778e-01, -7.52400458e-01,\n",
              "         -8.65390956e-01, -8.10665190e-01, -1.91085368e-01,\n",
              "          6.22546710e-02,  9.39342856e-01,  6.60155177e-01,\n",
              "          5.10392904e-01,  3.03855091e-01, -7.58785963e-01,\n",
              "          9.97947156e-01, -8.39390576e-01, -9.73821759e-01,\n",
              "         -6.96808040e-01, -4.71226066e-01, -9.92139816e-01,\n",
              "          9.27336872e-01,  3.11118126e-01,  6.17148519e-01,\n",
              "         -5.93245387e-01, -7.30744004e-01, -9.74081039e-01,\n",
              "          9.14183974e-01,  2.35106960e-01,  9.90232766e-01,\n",
              "         -4.98075426e-01, -9.59739447e-01, -7.62371182e-01,\n",
              "         -9.30913270e-01, -4.32068557e-02, -2.13116214e-01,\n",
              "         -6.06085479e-01, -2.81609744e-02, -9.69718456e-01,\n",
              "          6.36244059e-01,  6.35316193e-01,  5.37905514e-01,\n",
              "         -8.91036212e-01,  9.99303162e-01,  1.00000000e+00,\n",
              "          9.73003685e-01,  9.01396811e-01,  8.87466490e-01,\n",
              "         -9.99958754e-01, -6.90021813e-01,  9.99998033e-01,\n",
              "         -9.93730485e-01, -1.00000000e+00, -9.37510729e-01,\n",
              "         -8.12253177e-01,  2.70660579e-01, -1.00000000e+00,\n",
              "         -2.87079006e-01, -1.50920093e-01, -9.31140244e-01,\n",
              "          8.18555176e-01,  9.78329003e-01,  9.94965494e-01,\n",
              "         -1.00000000e+00,  8.81453633e-01,  9.30843115e-01,\n",
              "         -7.06026793e-01,  9.76767182e-01, -6.08330011e-01,\n",
              "          9.75543439e-01,  5.93019307e-01,  5.54318964e-01,\n",
              "         -2.44307116e-01,  4.22843605e-01, -9.68066275e-01,\n",
              "         -9.14158404e-01, -7.75702655e-01, -7.79753447e-01,\n",
              "          9.98873472e-01,  2.67525613e-01, -7.70680785e-01,\n",
              "         -9.30970252e-01,  6.98258281e-01, -1.79436088e-01,\n",
              "          1.48644954e-01, -9.69404280e-01, -3.27199519e-01,\n",
              "          7.69222558e-01,  8.38437378e-01,  2.74362981e-01,\n",
              "          4.46673781e-01, -6.88233852e-01,  4.38525349e-01,\n",
              "         -6.96205795e-02,  2.83885241e-01,  6.96684837e-01,\n",
              "         -9.55272675e-01, -5.49684286e-01, -3.89560938e-01,\n",
              "          3.75222951e-01, -7.64762104e-01, -9.54122961e-01,\n",
              "          9.69721198e-01, -4.86066520e-01,  9.72205639e-01,\n",
              "          1.00000000e+00,  7.64813483e-01, -9.13303614e-01,\n",
              "          6.57082558e-01,  4.31851983e-01, -7.01079071e-01,\n",
              "          1.00000000e+00,  8.67337108e-01, -9.83669639e-01,\n",
              "         -5.84471703e-01,  7.79540777e-01, -6.77889824e-01,\n",
              "         -7.74523795e-01,  9.99661028e-01, -3.41092914e-01,\n",
              "         -8.14479828e-01, -6.48069084e-01,  9.86272931e-01,\n",
              "         -9.94089305e-01,  9.97643054e-01, -8.94537687e-01,\n",
              "         -9.79997218e-01,  9.60477650e-01,  9.49231863e-01,\n",
              "         -6.83827937e-01, -7.17898369e-01,  2.86706626e-01,\n",
              "         -7.60040939e-01,  4.78332102e-01, -9.51963246e-01,\n",
              "          8.08321118e-01,  5.27614176e-01, -1.67665705e-01,\n",
              "          9.16267991e-01, -8.87898862e-01, -5.93430936e-01,\n",
              "          3.90307993e-01, -7.76923180e-01, -3.84818226e-01,\n",
              "          9.59038138e-01,  6.78381085e-01, -4.08702731e-01,\n",
              "         -1.99681446e-02, -4.68428701e-01, -7.41143227e-01,\n",
              "         -9.73734379e-01,  6.23253822e-01,  1.00000000e+00,\n",
              "         -4.31855381e-01,  8.94348681e-01, -5.72569609e-01,\n",
              "         -1.89499632e-02,  7.24832192e-02,  6.05421305e-01,\n",
              "          5.64563990e-01, -5.04034877e-01, -8.33653033e-01,\n",
              "          9.20378506e-01, -9.70664680e-01, -9.92627323e-01,\n",
              "          8.63119364e-01,  2.32818246e-01, -3.05338413e-01,\n",
              "          9.99999285e-01,  6.51024461e-01,  3.69558603e-01,\n",
              "          5.16951740e-01,  9.89937425e-01, -5.10576963e-02,\n",
              "          5.19780874e-01,  9.13519561e-01,  9.89344239e-01,\n",
              "         -4.06514257e-01,  6.72227561e-01,  8.66246045e-01,\n",
              "         -9.63320851e-01, -3.93905491e-01, -7.32534170e-01,\n",
              "          6.66498169e-02, -9.50428963e-01,  5.36765233e-02,\n",
              "         -9.64523554e-01,  9.78591144e-01,  9.72525120e-01,\n",
              "          5.02412796e-01,  3.42612594e-01,  8.20066929e-01,\n",
              "          1.00000000e+00, -8.37067783e-01,  5.97411096e-01,\n",
              "         -4.17201251e-01,  8.81285906e-01, -9.99911070e-01,\n",
              "         -8.37778032e-01, -4.66962039e-01, -2.72496462e-01,\n",
              "         -9.03814495e-01, -4.58637744e-01,  3.91833246e-01,\n",
              "         -9.79059398e-01,  9.10196245e-01,  8.29555392e-01,\n",
              "         -9.92893636e-01, -9.93933380e-01, -5.58821380e-01,\n",
              "          7.86011875e-01,  2.98600942e-01, -9.94314432e-01,\n",
              "         -8.16725254e-01, -6.58431828e-01,  9.07821834e-01,\n",
              "         -4.84595865e-01, -9.59578693e-01, -5.24700880e-01,\n",
              "         -4.26523089e-01,  5.39447308e-01, -3.51429671e-01,\n",
              "          6.03987992e-01,  8.84236515e-01,  6.91960096e-01,\n",
              "         -7.73553431e-01, -3.49986762e-01, -1.82105869e-01,\n",
              "         -8.09592426e-01,  9.06841397e-01, -8.09705973e-01,\n",
              "         -9.76247668e-01, -2.70705462e-01,  1.00000000e+00,\n",
              "         -5.54332614e-01,  8.93760264e-01,  7.55229652e-01,\n",
              "          7.80315995e-01, -1.99225336e-01,  3.35151017e-01,\n",
              "          9.55944002e-01,  3.82269770e-01, -7.57196724e-01,\n",
              "         -9.39319909e-01, -6.35581195e-01, -6.07328951e-01,\n",
              "          7.00571656e-01,  7.23613143e-01,  7.29011178e-01,\n",
              "          8.65883350e-01,  7.64537454e-01,  2.08821058e-01,\n",
              "         -6.98528811e-02, -5.64517744e-04,  9.99799371e-01,\n",
              "         -4.44099933e-01, -1.80671543e-01, -4.89859462e-01,\n",
              "         -2.91431367e-01, -4.25409138e-01, -1.98749244e-01,\n",
              "          1.00000000e+00,  3.56602043e-01,  7.75661469e-01,\n",
              "         -9.93823767e-01, -9.28070962e-01, -9.31738377e-01,\n",
              "          1.00000000e+00,  8.50040257e-01, -7.60715663e-01,\n",
              "          7.18036413e-01,  7.75469065e-01, -1.75161794e-01,\n",
              "          8.09469163e-01, -3.36547792e-01, -3.02385300e-01,\n",
              "          4.57468033e-01,  3.08043748e-01,  9.70231950e-01,\n",
              "         -6.18903935e-01, -9.75721240e-01, -5.94948649e-01,\n",
              "          5.63390732e-01, -9.66651022e-01,  9.99981403e-01,\n",
              "         -6.10340297e-01, -3.60574901e-01, -4.96435672e-01,\n",
              "         -4.91436154e-01,  4.47816610e-01,  2.87385155e-02,\n",
              "         -9.83154774e-01, -3.47387284e-01,  3.09110373e-01,\n",
              "          9.66638982e-01,  3.75864029e-01, -6.41106606e-01,\n",
              "         -8.90264690e-01,  8.92269015e-01,  8.31999958e-01,\n",
              "         -9.59132075e-01, -9.57766354e-01,  9.71166253e-01,\n",
              "         -9.84971225e-01,  7.67819345e-01,  1.00000000e+00,\n",
              "          3.83998841e-01,  4.38051134e-01,  3.52292210e-01,\n",
              "         -4.46136117e-01,  4.46569115e-01, -6.90631390e-01,\n",
              "          6.74425185e-01, -9.59155798e-01, -4.53284919e-01,\n",
              "         -2.96152413e-01,  3.57684195e-01, -2.41154522e-01,\n",
              "         -5.88313937e-01,  7.63308167e-01,  3.13667208e-01,\n",
              "         -6.03100598e-01, -6.84795499e-01, -2.60147035e-01,\n",
              "          5.75160146e-01,  9.16844189e-01, -3.56800050e-01,\n",
              "         -2.31557772e-01,  1.15727820e-01, -1.77118838e-01,\n",
              "         -9.47563529e-01, -5.23141861e-01, -6.04617715e-01,\n",
              "         -9.99998510e-01,  5.41667640e-01, -1.00000000e+00,\n",
              "          6.60001874e-01,  3.39037061e-01, -2.57962316e-01,\n",
              "          8.98433864e-01,  3.58503431e-01,  7.80091882e-01,\n",
              "         -8.63456070e-01, -9.04243648e-01,  2.35173926e-01,\n",
              "          8.47542107e-01, -4.83704835e-01, -7.76437283e-01,\n",
              "         -7.77086675e-01,  4.51546788e-01, -1.20643899e-01,\n",
              "          3.45337808e-01, -7.58304656e-01,  7.38663375e-01,\n",
              "         -2.54878223e-01,  1.00000000e+00,  1.56726748e-01,\n",
              "         -6.47172749e-01, -9.80846465e-01,  3.21544796e-01,\n",
              "         -3.49479914e-01,  1.00000000e+00, -8.88086021e-01,\n",
              "         -9.70758677e-01,  4.17613775e-01, -6.59506202e-01,\n",
              "         -8.39061618e-01,  4.56445932e-01,  7.08392337e-02,\n",
              "         -8.59648764e-01, -9.68725622e-01,  9.56583917e-01,\n",
              "          8.95310938e-01, -6.79162502e-01,  7.91996121e-01,\n",
              "         -3.77204835e-01, -5.99682093e-01,  1.89219326e-01,\n",
              "          9.34770346e-01,  9.87944603e-01,  7.07965016e-01,\n",
              "          9.21087861e-01, -1.59540847e-01, -4.83467698e-01,\n",
              "          9.76640463e-01,  2.95251966e-01,  5.32053053e-01,\n",
              "          3.22657973e-01,  1.00000000e+00,  4.97991651e-01,\n",
              "         -9.31000769e-01, -3.24744046e-01, -9.82841551e-01,\n",
              "         -2.67996252e-01, -9.52166021e-01,  4.53916639e-01,\n",
              "          3.94372225e-01,  9.26190078e-01, -3.09752166e-01,\n",
              "          9.69366491e-01, -9.40263689e-01,  1.66798413e-01,\n",
              "         -8.32232893e-01, -7.04411089e-01,  5.49370289e-01,\n",
              "         -9.30373430e-01, -9.88702476e-01, -9.91572201e-01,\n",
              "          7.38682628e-01, -5.26327193e-01, -9.29531008e-02,\n",
              "          2.77956039e-01,  2.54385531e-01,  5.55892766e-01,\n",
              "          5.70780277e-01, -1.00000000e+00,  9.51999605e-01,\n",
              "          5.82980871e-01,  9.13394034e-01,  9.78624403e-01,\n",
              "          7.49032199e-01,  7.39971817e-01,  3.71186525e-01,\n",
              "         -9.89660680e-01, -9.84848499e-01, -5.31397820e-01,\n",
              "         -3.88979554e-01,  8.49413693e-01,  8.17017019e-01,\n",
              "          8.92696738e-01,  6.16891921e-01, -5.75284481e-01,\n",
              "         -2.86467224e-01, -7.60570765e-01, -7.78939366e-01,\n",
              "         -9.94441628e-01,  5.72188199e-01, -7.72194982e-01,\n",
              "         -9.57696259e-01,  9.67420697e-01, -2.17978910e-01,\n",
              "         -1.75552815e-01, -3.26557368e-01, -9.06777859e-01,\n",
              "          9.35597360e-01,  7.66239345e-01,  1.90595776e-01,\n",
              "          1.53928965e-01,  5.40217042e-01,  9.02483523e-01,\n",
              "          9.40388918e-01,  9.88884807e-01, -9.10143971e-01,\n",
              "          7.88359702e-01, -8.31382871e-01,  6.11195266e-01,\n",
              "          8.21669102e-01, -9.41967666e-01,  3.75133097e-01,\n",
              "          5.49405575e-01, -6.15318537e-01,  3.91501725e-01,\n",
              "         -3.66627067e-01, -9.74752426e-01,  8.88878345e-01,\n",
              "         -3.62838060e-01,  6.53205574e-01, -5.35069764e-01,\n",
              "         -2.21280716e-02, -4.40158010e-01, -3.87567252e-01,\n",
              "         -7.89354861e-01, -6.70902312e-01,  6.87370062e-01,\n",
              "          4.34680045e-01,  9.07510698e-01,  9.13953960e-01,\n",
              "         -1.07544795e-01, -8.54991615e-01, -3.22965652e-01,\n",
              "         -7.80992687e-01, -9.35075343e-01,  9.56620991e-01,\n",
              "         -2.46967211e-01, -1.84676230e-01,  7.18141794e-01,\n",
              "          1.66833803e-01,  9.54272568e-01,  5.20279586e-01,\n",
              "         -5.11346340e-01, -3.58430266e-01, -7.76734531e-01,\n",
              "          9.01378870e-01, -6.45810187e-01, -6.68203056e-01,\n",
              "         -6.79575622e-01,  8.30889285e-01,  4.56940055e-01,\n",
              "          9.99998093e-01, -8.61587346e-01, -9.52708602e-01,\n",
              "         -5.74054658e-01, -4.75623190e-01,  5.11585712e-01,\n",
              "         -7.02607274e-01, -1.00000000e+00,  5.05624294e-01,\n",
              "         -6.52045786e-01,  8.13730776e-01, -8.72139215e-01,\n",
              "          8.09319794e-01, -8.18221927e-01, -9.88196373e-01,\n",
              "         -4.00082469e-01,  3.38945359e-01,  7.67013729e-01,\n",
              "         -5.16352832e-01, -8.75940681e-01,  6.15952194e-01,\n",
              "         -7.52709746e-01,  9.89328504e-01,  8.95710588e-01,\n",
              "         -6.14249945e-01,  2.19649568e-01,  7.52754331e-01,\n",
              "         -8.20389569e-01, -8.05691242e-01,  9.38039303e-01]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(1, 6, 768), dtype=float32, numpy=\n",
              " array([[[-0.079475  ,  0.00580774, -0.31414056, ..., -0.45097274,\n",
              "           0.2933315 ,  0.23387697],\n",
              "         [ 0.3931604 ,  0.50336325,  0.24021432, ..., -0.32635632,\n",
              "           0.34986126,  0.20673184],\n",
              "         [ 0.35789314,  0.10767043, -0.04988939, ..., -0.508227  ,\n",
              "           0.2504883 , -0.26268762],\n",
              "         [-0.2989224 , -0.24708708,  0.07151417, ..., -0.33809978,\n",
              "           0.12699474, -0.09681911],\n",
              "         [-0.3681531 , -0.71465254, -0.21032533, ...,  0.35395187,\n",
              "           0.33438638, -0.6233479 ],\n",
              "         [ 0.8869229 , -0.16996966, -0.29173604, ...,  0.05816477,\n",
              "          -0.5775988 , -0.32075295]]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6DD3k3qPLDQ"
      },
      "source": [
        "class DCNNBERTEmbedding(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 nb_filters=50,\n",
        "                 FFN_units=512,\n",
        "                 nb_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 name=\"dcnn\"):\n",
        "        super(DCNNBERTEmbedding, self).__init__(name=name)\n",
        "        \n",
        "        self.bert_layer = hub.KerasLayer(\n",
        "            \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "            trainable=False)\n",
        "        \n",
        "        self.bigram = layers.Conv1D(filters=nb_filters,\n",
        "                                    kernel_size=2,\n",
        "                                    padding=\"valid\",\n",
        "                                    activation=\"relu\")\n",
        "        self.trigram = layers.Conv1D(filters=nb_filters,\n",
        "                                     kernel_size=3,\n",
        "                                     padding=\"valid\",\n",
        "                                     activation=\"relu\")\n",
        "        self.fourgram = layers.Conv1D(filters=nb_filters,\n",
        "                                      kernel_size=4,\n",
        "                                      padding=\"valid\",\n",
        "                                      activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=FFN_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if nb_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=nb_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def embed_with_bert(self, all_tokens):\n",
        "        _, embs = self.bert_layer([all_tokens[:, 0, :],\n",
        "                                   all_tokens[:, 1, :],\n",
        "                                   all_tokens[:, 2, :]])\n",
        "        return embs\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        x = self.embed_with_bert(inputs)\n",
        "\n",
        "        x_1 = self.bigram(x) # (batch_size, nb_filters, seq_len-1)\n",
        "        x_1 = self.pool(x_1) # (batch_size, nb_filters)\n",
        "        x_2 = self.trigram(x) # (batch_size, nb_filters, seq_len-2)\n",
        "        x_2 = self.pool(x_2) # (batch_size, nb_filters)\n",
        "        x_3 = self.fourgram(x) # (batch_size, nb_filters, seq_len-3)\n",
        "        x_3 = self.pool(x_3) # (batch_size, nb_filters)\n",
        "        \n",
        "        merged = tf.concat([x_1, x_2, x_3], axis=-1) # (batch_size, 3 * nb_filters)\n",
        "        merged = self.dense_1(merged)\n",
        "        merged = self.dropout(merged, training)\n",
        "        output = self.last_dense(merged)\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSix1l4jkIxp"
      },
      "source": [
        "# Stage 4: Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhfUFvWEPOIf"
      },
      "source": [
        "NB_FILTERS = 100\n",
        "FFN_UNITS = 256\n",
        "NB_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NB_EPOCHS = 2"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMtdiWmwv6rD"
      },
      "source": [
        "Dcnn = DCNNBERTEmbedding(nb_filters=NB_FILTERS,\n",
        "                         FFN_units=FFN_UNITS,\n",
        "                         nb_classes=NB_CLASSES,\n",
        "                         dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6apbd7FrwPYo"
      },
      "source": [
        "if NB_CLASSES == 2:\n",
        "    Dcnn.compile(loss=\"binary_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"accuracy\"])\n",
        "else:\n",
        "    Dcnn.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                 optimizer=\"adam\",\n",
        "                 metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78cceSGCw1XC"
      },
      "source": [
        "checkpoint_path = \"./content/drive/MyDrive/BERT_UDEMY/models/cnn_sentiment_bert_embedding\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(Dcnn=Dcnn)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=1)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print(\"Latest Checkpoint restored!\")"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YIF5trzx7RA"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        ckpt_manager.save()\n",
        "        print(\"Checkpoint saved at {}.\".format(checkpoint_path))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrT8oWZzQNmW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "181fbbcb-59de-4661-dbb6-58217d867724"
      },
      "source": [
        "Dcnn.fit(train_dataset,\n",
        "         epochs=NB_EPOCHS,\n",
        "         callbacks=[MyCustomCallback()])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "  40460/Unknown - 4801s 117ms/step - loss: 0.3968 - accuracy: 0.8223"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-08acfa05b503>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m Dcnn.fit(train_dataset,\n\u001b[1;32m      2\u001b[0m          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNB_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m          callbacks=[MyCustomCallback()])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IiDW919kQQK"
      },
      "source": [
        "# Stage 5: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MthhNfnG1TPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92b559a-0258-437c-ab4c-353878bc495f"
      },
      "source": [
        "results = Dcnn.evaluate(test_dataset)\n",
        "print(results)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4513/4513 [==============================] - 291s 64ms/step - loss: 0.3503 - accuracy: 0.8509\n",
            "[0.35029757022857666, 0.8509306311607361]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-jrRvtl1xuk"
      },
      "source": [
        "def get_prediction(sentence):\n",
        "    tokens = encode_sentence(sentence)\n",
        "\n",
        "    input_ids = get_ids(tokens)\n",
        "    input_mask = get_mask(tokens)\n",
        "    segment_ids = get_segments(tokens)\n",
        "\n",
        "    inputs = tf.stack(\n",
        "        [tf.cast(input_ids, dtype=tf.int32),\n",
        "         tf.cast(input_mask, dtype=tf.int32),\n",
        "         tf.cast(segment_ids, dtype=tf.int32)],\n",
        "         axis=0)\n",
        "    inputs = tf.expand_dims(inputs, 0)\n",
        "\n",
        "    output = Dcnn(inputs, training=False)\n",
        "\n",
        "    sentiment = math.floor(output*2)\n",
        "\n",
        "    if sentiment == 0:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: negative.\".format(\n",
        "            output))\n",
        "    elif sentiment == 1:\n",
        "        print(\"Output of the model: {}\\nPredicted sentiment: positive.\".format(\n",
        "            output))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk8V2bdvwfCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6bf14ea-bdd8-4056-a87a-caae609694ee"
      },
      "source": [
        "get_prediction(\"This movie was pretty interesting.\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the model: [[0.8897263]]\n",
            "Predicted sentiment: positive.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilgSppeGParJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5a1289c-834e-4e1e-ac4c-60564800a92f"
      },
      "source": [
        "get_prediction(\"I'd rather not do that again.\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the model: [[0.28766114]]\n",
            "Predicted sentiment: negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_prediction(\"Wow. its working\")"
      ],
      "metadata": {
        "id": "q_Gsj1U_twlB",
        "outputId": "d5d84dc6-5c7c-4ded-e296-e4ede8821273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of the model: [[0.7819323]]\n",
            "Predicted sentiment: positive.\n"
          ]
        }
      ]
    }
  ]
}